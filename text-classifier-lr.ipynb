{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPw1Uo+EaQpC51Fkb4WYq23",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nice-digital/text-classifier/blob/main/text-classifier-lr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text classifier Colab**\n",
        "\n",
        "This Colab notebook allows you to categorise a set of scientific papers into two categories. This is experimental code\n",
        "\n",
        "**Note**: Name your training file *training.csv*  and test file *testing.csv* (*title* column should be named 'Title' or 'title' and *abstract* column if present should be named 'Abstract' or 'abstract'), and upload it by pressing the upload button on the top left of the left sidebar. The results will appear in a folder named *RESULTS*. RESULTS folder will be automatically created by the code.\n"
      ],
      "metadata": {
        "id": "J3XQyHVQAmMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Python packages { form-width: \"20%\" }\n",
        "\n",
        "#@markdown Please execute this cell by pressing the _Play_ button\n",
        "#@markdown on the left to download and import third-party software\n",
        "#@markdown in this Colab notebook.\n",
        "\n",
        "#@markdown This installs the software on the Colab\n",
        "#@markdown notebook in the cloud and not on your computer.\n",
        "from IPython.utils import io\n",
        "try:\n",
        "  with io.capture_output() as captured:\n",
        "    %shell pip install scispacy\n",
        "    %shell pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_md-0.5.0.tar.gz\n",
        "    %shell pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz\n",
        "    %shell pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bionlp13cg_md-0.5.1.tar.gz\n",
        "    %shell pip install pyLDAvis==2.1.2\n",
        "    %shell pip install import-ipynb\n",
        "    %shell pip install pandas\n",
        "    %shell pip install shutup\n",
        "\n",
        "except subprocess.CalledProcessError:\n",
        "  print(captured)\n",
        "  raise\n",
        "import shutup\n",
        "shutup.please()\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import spacy\n",
        "import scispacy\n",
        "import pandas as pd\n",
        "from scispacy.abbreviation import AbbreviationDetector\n",
        "\n",
        "from pathlib import Path\n",
        "import collections\n",
        "import csv\n",
        "import multiprocessing as mp\n",
        "from multiprocessing import Pool\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "cpu_count = mp.cpu_count()\n",
        "\n",
        "pd. set_option('display.max_colwidth', None)"
      ],
      "metadata": {
        "id": "yNF5tewRA4Dn",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "cI9oDdX-2hXb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create train/test datasets from human/animal datasets { form-width: \"20%\" }\n",
        "animal = pd.read_csv('Animal_2200.csv')\n",
        "human = pd.read_csv('human_2400.csv')\n",
        "\n",
        "#add target variable\n",
        "animal['target'] = 0\n",
        "human['target'] = 1\n",
        "\n",
        "print(animal.columns)\n",
        "print(human.columns)\n",
        "\n",
        "#combine & shuffle the datasets\n",
        "combined_data = pd.concat([animal, human], axis=0)\n",
        "shuffled_combined_df = combined_data.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "#create a 80-20 split from it\n",
        "training, testing = train_test_split(shuffled_combined_df, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "E46oKVfi0KHs",
        "outputId": "78eb3e53-01de-4d52-f142-b5963cf37857",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Title', 'Abstract', 'Primary Author', 'Journal', 'Year', 'Volume',\n",
            "       'Issue', 'Pages', 'Comments', 'Eppi ID', 'target'],\n",
            "      dtype='object')\n",
            "Index(['Title', 'Abstract', 'Primary Author', 'Journal', 'Year', 'Volume',\n",
            "       'Issue', 'Pages', 'Comments', 'Eppi ID', 'target'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title File settings to get started  { form-width: \"20%\" }\n",
        "\n",
        "#@markdown Please ensure the training.csv and testing.csv are uploaded and execute this cell by pressing the _Play_ button\n",
        "#@markdown on the left\n",
        "\n",
        "#@markdown The training.csv and testing.csv files should have 'title', optional 'abstract' fields. Additionally the file should have a 'target' field\n",
        "#@markdown which indicates whether the title/abstract is an include (coded as 1) or exclude (coded as 0)\n",
        "TRAIN_PATH = 'training.csv'\n",
        "TEST_PATH = 'testing.csv'\n",
        "\n",
        "results_folder = 'RESULTS'\n",
        "RESULTS_FOLDER = results_folder     #***user input\n",
        "if not os.path.isdir(RESULTS_FOLDER):\n",
        "    os.makedirs(RESULTS_FOLDER)\n",
        "RESULTS_PATH = Path(RESULTS_FOLDER)"
      ],
      "metadata": {
        "id": "XDSMaZGDI-Ko",
        "cellView": "form"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Read in input data as separate training.csv and testing.csv. **Ignore** this block if human/animal data was uploaded above { form-width: \"20%\" }\n",
        "try:\n",
        "    training = pd.read_csv(TRAIN_PATH)\n",
        "    orig_colnames = training.columns\n",
        "    print(orig_colnames)\n",
        "\n",
        "    testing = pd.read_csv(TEST_PATH)\n",
        "\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    raise"
      ],
      "metadata": {
        "cellView": "form",
        "id": "49646FC321sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Read in input data { form-width: \"20%\" }\n",
        "rename_map = {'Title': 'title', 'Abstract': 'abstract'}\n",
        "training.rename(columns = rename_map, inplace = True)\n",
        "testing.rename(columns = rename_map, inplace = True)\n",
        "print(\"Number of studies in the training dataset: \" + str(training.shape[0]))\n",
        "print(\"Number of studies in the training dataset: \" + str(testing.shape[0]))\n",
        "\n",
        "#rename the columns so that the relevant column names are 'title' and 'abstract'\n",
        "\n",
        "try:\n",
        "  training['title_orig'] = training['title']\n",
        "  testing['title_orig'] = testing['title']\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "  print(\"Error- No title detected! Title is needed!\")\n",
        "  raise\n",
        "\n",
        "# drop any duplicates based on 'title'\n",
        "training.drop_duplicates(subset=['title'], inplace=True)\n",
        "testing.drop_duplicates(subset=['title'], inplace=True)\n",
        "print(\"Number of studies in the training dataset after de-dupe: \" + str(training.shape[0]))\n",
        "print(\"Number of studies in the testing dataset after de-dupe: \" + str(testing.shape[0]))\n",
        "\n",
        "training['titleabstract'] = training['title'] + \" \" + training['abstract']\n",
        "training['titleabstract'] = training['titleabstract'].str.lower()\n",
        "\n",
        "testing['titleabstract'] = testing['title'] + \" \" + testing['abstract']\n",
        "testing['titleabstract'] = testing['titleabstract'].str.lower()"
      ],
      "metadata": {
        "id": "eR8-4xBMB7nQ",
        "cellView": "form",
        "outputId": "f2bf3b51-3cd5-4325-9874-51ed995df3b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of studies in the training dataset: 3698\n",
            "Number of studies in the training dataset: 925\n",
            "Number of studies in the training dataset after de-dupe: 3695\n",
            "Number of studies in the testing dataset after de-dupe: 925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fit logistic regression model (in progress) { form-width: \"20%\" }\n",
        "\n",
        "#A sklearn pipeline comprising of tf-idf vectorizer (using tri-gram) and logistic regression model. The parameters for logistic regression\n",
        "#are taken from prior hyper-parameter tuning.\n",
        "text_clf = Pipeline([\n",
        "                ('tfidfvect', TfidfVectorizer(ngram_range = (3,3), stop_words = 'english')),\n",
        "                ('clf', LogisticRegression(C=100, max_iter = 5000, solver = 'liblinear', penalty = 'l2', class_weight = 'balanced')),\n",
        "               ])\n",
        "y_train = training['target']\n",
        "model = text_clf.fit(training['titleabstract'].astype(str),y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "0ivxu5aJBbR5",
        "cellView": "form"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Predict category and evaluate performance (in progress) { form-width: \"20%\" }\n",
        "\n",
        "#Using the model that was fit to the training data above, evaluate the model's performance on test data.\n",
        "data = testing['titleabstract'].astype(str)\n",
        "y_test = testing['target']\n",
        "yhat = model.predict(data)\n",
        "yhat_probs = model.predict_proba(data)[:,1]\n",
        "yhat_adjusted = np.zeros(data.shape[0], dtype=int)\n",
        "THRESHOLD = 0.4\n",
        "yhat_adjusted[yhat_probs >= THRESHOLD] = 1\n",
        "\n",
        "report_dict = {}\n",
        "decimal_places = 3\n",
        "report_dict['Accuracy'] = accuracy_score(y_test, yhat_adjusted).round(decimal_places)\n",
        "report_dict['Precision'] = precision_score(y_test,yhat_adjusted).round(decimal_places)\n",
        "report_dict['Recall'] = recall_score(y_test, yhat_adjusted, average = 'binary').round(decimal_places)\n",
        "report_dict['F1-Score'] = f1_score(y_test, yhat_adjusted).round(decimal_places)\n",
        "report_dict['ROC_AUC'] = roc_auc_score(y_test, yhat_adjusted).round(decimal_places)\n",
        "cm = confusion_matrix(y_test, yhat_adjusted)\n",
        "FP = cm[0][1]\n",
        "TN = cm[0][0]\n",
        "FN = cm[1][0]\n",
        "TP = cm[1][1]\n",
        "specificity = (TN / (TN+FP)).round(decimal_places)\n",
        "FPR = (FP/(FP+TN)).round(decimal_places)\n",
        "FNR = (FN/(FN+TP)).round(decimal_places)\n",
        "report_dict['FPR'] = FPR\n",
        "report_dict['FNR'] = FNR\n",
        "report_dict['Specificity'] = specificity\n",
        "\n",
        "print('Classification report:\\n{}'.format(report_dict))\n"
      ],
      "metadata": {
        "id": "hdVqVB-BIfVk",
        "cellView": "form",
        "outputId": "0d5e8c2f-b80c-4121-898b-aecc04f45bfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report:\n",
            "{'Accuracy': 0.795, 'Precision': 0.719, 'Recall': 0.961, 'F1-Score': 0.823, 'ROC_AUC': 0.796, 'FPR': 0.369, 'FNR': 0.039, 'Specificity': 0.631}\n"
          ]
        }
      ]
    }
  ]
}