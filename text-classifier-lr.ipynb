{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nice-digital/text-classifier/blob/main/text-classifier-lr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text classifier Colab**\n",
        "\n",
        "This Colab notebook allows you to categorise a set of scientific papers into two categories. This is experimental code\n",
        "\n",
        "**Note**: Name your training file *training.csv*  and test file *testing.csv* (*title* column should be named 'Title' or 'title' and *abstract* column if present should be named 'Abstract' or 'abstract'), and upload it by pressing the upload button on the top left of the left sidebar. The results will appear in a folder named *RESULTS*. RESULTS folder will be automatically created by the code.\n"
      ],
      "metadata": {
        "id": "J3XQyHVQAmMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Python packages { form-width: \"20%\" }\n",
        "\n",
        "#@markdown Please execute this cell by pressing the _Play_ button\n",
        "#@markdown on the left to download and import third-party software\n",
        "#@markdown in this Colab notebook.\n",
        "\n",
        "#@markdown This installs the software on the Colab\n",
        "#@markdown notebook in the cloud and not on your computer.\n",
        "from IPython.utils import io\n",
        "try:\n",
        "  with io.capture_output() as captured:\n",
        "    # %shell pip install scispacy\n",
        "    # %shell pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_md-0.5.0.tar.gz\n",
        "    # %shell pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz\n",
        "    # %shell pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bionlp13cg_md-0.5.1.tar.gz\n",
        "    %shell pip install pyLDAvis==2.1.2\n",
        "    %shell pip install import-ipynb\n",
        "    %shell pip install pandas\n",
        "    %shell pip install shutup\n",
        "\n",
        "except subprocess.CalledProcessError:\n",
        "  print(captured)\n",
        "  raise\n",
        "import shutup\n",
        "shutup.please()\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import spacy\n",
        "# import scispacy\n",
        "import pandas as pd\n",
        "# from scispacy.abbreviation import AbbreviationDetector\n",
        "\n",
        "from pathlib import Path\n",
        "import collections\n",
        "import csv\n",
        "import multiprocessing as mp\n",
        "from multiprocessing import Pool\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "\n",
        "cpu_count = mp.cpu_count()\n",
        "\n",
        "pd. set_option('display.max_colwidth', None)"
      ],
      "metadata": {
        "id": "yNF5tewRA4Dn",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create train/test datasets from human/animal datasets { form-width: \"20%\" }\n",
        "animal = pd.read_csv('excludes_Animal_2200.csv')\n",
        "human = pd.read_csv('includes_human_2400.csv')\n",
        "\n",
        "#add target variable\n",
        "animal['target'] = 0\n",
        "human['target'] = 1\n",
        "\n",
        "print(animal.columns)\n",
        "print(human.columns)\n",
        "\n",
        "#combine & shuffle the datasets\n",
        "combined_data = pd.concat([animal, human], axis=0)\n",
        "shuffled_combined_df = combined_data.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "#create a 80-20 split from it\n",
        "training, testing = train_test_split(shuffled_combined_df, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "E46oKVfi0KHs",
        "outputId": "b5db9533-813e-4b93-a90a-05760ece206d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Title', 'Abstract', 'Primary Author', 'Journal', 'Year', 'Volume',\n",
            "       'Issue', 'Pages', 'Comments', 'Eppi ID', 'target'],\n",
            "      dtype='object')\n",
            "Index(['Title', 'Abstract', 'Primary Author', 'Journal', 'Year', 'Volume',\n",
            "       'Issue', 'Pages', 'Comments', 'Eppi ID', 'target'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title File settings to get started  { form-width: \"20%\" }\n",
        "\n",
        "#@markdown Please ensure the training.csv and testing.csv are uploaded and execute this cell by pressing the _Play_ button\n",
        "#@markdown on the left\n",
        "\n",
        "#@markdown The training.csv and testing.csv files should have 'title', optional 'abstract' fields. Additionally the file should have a 'target' field\n",
        "#@markdown which indicates whether the title/abstract is an include (coded as 1) or exclude (coded as 0)\n",
        "TRAIN_PATH = 'training.csv'\n",
        "TEST_PATH = 'testing.csv'\n",
        "\n",
        "results_folder = 'RESULTS'\n",
        "RESULTS_FOLDER = results_folder     #***user input\n",
        "if not os.path.isdir(RESULTS_FOLDER):\n",
        "    os.makedirs(RESULTS_FOLDER)\n",
        "RESULTS_PATH = Path(RESULTS_FOLDER)"
      ],
      "metadata": {
        "id": "XDSMaZGDI-Ko",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Read in input data as separate training.csv and testing.csv. **Ignore** this block if human/animal data was uploaded above { form-width: \"20%\" }\n",
        "try:\n",
        "    training = pd.read_csv(TRAIN_PATH)\n",
        "    orig_colnames = training.columns\n",
        "    print(orig_colnames)\n",
        "\n",
        "    testing = pd.read_csv(TEST_PATH)\n",
        "\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    raise"
      ],
      "metadata": {
        "cellView": "form",
        "id": "49646FC321sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Read in input data { form-width: \"20%\" }\n",
        "rename_map = {'Title': 'title', 'Abstract': 'abstract'}\n",
        "training.rename(columns = rename_map, inplace = True)\n",
        "testing.rename(columns = rename_map, inplace = True)\n",
        "print(\"Number of studies in the training dataset: \" + str(training.shape[0]))\n",
        "print(\"Number of studies in the training dataset: \" + str(testing.shape[0]))\n",
        "\n",
        "#rename the columns so that the relevant column names are 'title' and 'abstract'\n",
        "\n",
        "try:\n",
        "  training['title_orig'] = training['title']\n",
        "  testing['title_orig'] = testing['title']\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "  print(\"Error- No title detected! Title is needed!\")\n",
        "  raise\n",
        "\n",
        "# drop any duplicates based on 'title'\n",
        "training.drop_duplicates(subset=['title'], inplace=True)\n",
        "testing.drop_duplicates(subset=['title'], inplace=True)\n",
        "print(\"Number of studies in the training dataset after de-dupe: \" + str(training.shape[0]))\n",
        "print(\"Number of studies in the testing dataset after de-dupe: \" + str(testing.shape[0]))\n",
        "\n",
        "training['titleabstract'] = training['title'] + \" \" + training['abstract']\n",
        "training['titleabstract'] = training['titleabstract'].str.lower()\n",
        "\n",
        "testing['titleabstract'] = testing['title'] + \" \" + testing['abstract']\n",
        "testing['titleabstract'] = testing['titleabstract'].str.lower()"
      ],
      "metadata": {
        "id": "eR8-4xBMB7nQ",
        "outputId": "64f1e726-4d4d-47da-873b-c0ebb0a6b8d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of studies in the training dataset: 3693\n",
            "Number of studies in the training dataset: 925\n",
            "Number of studies in the training dataset after de-dupe: 3693\n",
            "Number of studies in the testing dataset after de-dupe: 925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fit logistic regression model (in progress) { form-width: \"20%\" }\n",
        "\n",
        "#A sklearn pipeline comprising of tf-idf vectorizer (using tri-gram) and logistic regression model. The parameters for logistic regression\n",
        "#are taken from prior hyper-parameter tuning.\n",
        "text_clf = Pipeline([\n",
        "                ('tfidfvect', TfidfVectorizer(ngram_range = (3,3), stop_words = 'english')),\n",
        "                ('clf', LogisticRegression(C=100, max_iter = 5000, solver = 'liblinear', penalty = 'l2', class_weight = 'balanced')),\n",
        "               ])\n",
        "y_train = training['target']\n",
        "model = text_clf.fit(training['titleabstract'].astype(str),y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "0ivxu5aJBbR5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Predict category and evaluate performance (in progress) { form-width: \"20%\" }\n",
        "\n",
        "#Using the model that was fit to the training data above, evaluate the model's performance on test data.\n",
        "data = testing['titleabstract'].astype(str)\n",
        "y_test = testing['target']\n",
        "yhat = model.predict(data)\n",
        "yhat_probs = model.predict_proba(data)[:,1]\n",
        "yhat_adjusted = np.zeros(data.shape[0], dtype=int)\n",
        "THRESHOLD = 0.4\n",
        "yhat_adjusted[yhat_probs >= THRESHOLD] = 1\n",
        "\n",
        "report_dict = {}\n",
        "decimal_places = 3\n",
        "report_dict['Accuracy'] = accuracy_score(y_test, yhat_adjusted).round(decimal_places)\n",
        "report_dict['Precision'] = precision_score(y_test,yhat_adjusted).round(decimal_places)\n",
        "report_dict['Recall'] = recall_score(y_test, yhat_adjusted, average = 'binary').round(decimal_places)\n",
        "report_dict['F1-Score'] = f1_score(y_test, yhat_adjusted).round(decimal_places)\n",
        "report_dict['ROC_AUC'] = roc_auc_score(y_test, yhat_adjusted).round(decimal_places)\n",
        "cm = confusion_matrix(y_test, yhat_adjusted)\n",
        "FP = cm[0][1]\n",
        "TN = cm[0][0]\n",
        "FN = cm[1][0]\n",
        "TP = cm[1][1]\n",
        "specificity = (TN / (TN+FP)).round(decimal_places)\n",
        "FPR = (FP/(FP+TN)).round(decimal_places)\n",
        "FNR = (FN/(FN+TP)).round(decimal_places)\n",
        "report_dict['FPR'] = FPR\n",
        "report_dict['FNR'] = FNR\n",
        "report_dict['Specificity'] = specificity\n",
        "\n",
        "print('Classification report:\\n{}'.format(report_dict))\n"
      ],
      "metadata": {
        "id": "hdVqVB-BIfVk",
        "cellView": "form",
        "outputId": "d95029f8-6350-42e4-b0e9-f9314314d106",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report:\n",
            "{'Accuracy': 0.826, 'Precision': 0.764, 'Recall': 0.974, 'F1-Score': 0.856, 'ROC_AUC': 0.816, 'FPR': 0.343, 'FNR': 0.026, 'Specificity': 0.657}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WJcbbJmFM7W8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing**\n"
      ],
      "metadata": {
        "id": "RFhHJYnhafa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Basic Preprocessing { form-width: \"20%\" }\n",
        "\n",
        "# Load dataset\n",
        "animal = pd.read_csv('excludes_Animal_2200.csv')\n",
        "human = pd.read_csv('includes_human_2400.csv')\n",
        "\n",
        "# prompt: shape of the df\n",
        "(animal.shape), (human.shape)\n",
        "\n",
        "#add target variable\n",
        "animal['target'] = 0\n",
        "human['target'] = 1"
      ],
      "metadata": {
        "id": "DsMgFP-AmvTd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "animal.isna().sum(), human.isna().sum()\n"
      ],
      "metadata": {
        "id": "TV4NGOzZubv1",
        "outputId": "37fa6d23-7055-450a-e661-360a587a814f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Title                0\n",
              " Abstract            61\n",
              " Primary Author       4\n",
              " Journal              0\n",
              " Year                 0\n",
              " Volume              30\n",
              " Issue              687\n",
              " Pages              190\n",
              " Comments          2212\n",
              " Eppi ID              0\n",
              " target               0\n",
              " dtype: int64,\n",
              " Title                0\n",
              " Abstract           410\n",
              " Primary Author       0\n",
              " Journal              0\n",
              " Year                 2\n",
              " Volume              25\n",
              " Issue              113\n",
              " Pages                6\n",
              " Comments          2411\n",
              " Eppi ID              0\n",
              " target               0\n",
              " dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "animal.columns, human.columns"
      ],
      "metadata": {
        "id": "OStO2DSGsxcs",
        "outputId": "2b9288d6-0aad-4cae-931c-1961928b3aa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Index(['Title', 'Abstract', 'Primary Author', 'Journal', 'Year', 'Volume',\n",
              "        'Issue', 'Pages', 'Comments', 'Eppi ID', 'target'],\n",
              "       dtype='object'),\n",
              " Index(['Title', 'Abstract', 'Primary Author', 'Journal', 'Year', 'Volume',\n",
              "        'Issue', 'Pages', 'Comments', 'Eppi ID', 'target'],\n",
              "       dtype='object'))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deleting unwanted columns"
      ],
      "metadata": {
        "id": "Q5nE3WZNrwjB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "human.drop(columns=['Primary Author', 'Journal', 'Year', 'Volume',\n",
        "       'Issue', 'Pages', 'Comments', 'Eppi ID', 'target'], inplace=True)"
      ],
      "metadata": {
        "id": "6OtJxwrGrr6H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "animal.drop(columns=['Primary Author', 'Journal', 'Year', 'Volume',\n",
        "       'Issue', 'Pages', 'Comments', 'Eppi ID', 'target'], inplace=True)"
      ],
      "metadata": {
        "id": "ovNo2hZG1MwQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "animal.columns.shape"
      ],
      "metadata": {
        "id": "sXPwqbYshHo_",
        "outputId": "6dd65610-7c03-4d51-8c1d-6954d652e73c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "human.columns"
      ],
      "metadata": {
        "id": "pgti6WkU2MvO",
        "outputId": "5b53bb0d-b6b8-417c-e121-382d39b5efa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Title', 'Abstract'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "animal.isna().sum()"
      ],
      "metadata": {
        "id": "xDExyZLg3idi",
        "outputId": "d448bb23-c1b9-49c6-9587-2b90dd4e454d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Title        0\n",
              "Abstract    61\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "human.isnull().sum()"
      ],
      "metadata": {
        "id": "XVfUEI2q3pIR",
        "outputId": "c616ce1f-197c-4113-8e4b-aa490ff59fb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Title         0\n",
              "Abstract    410\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# animal.sample(3)"
      ],
      "metadata": {
        "id": "5jvEogi-6g1Y"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "animal.dropna(inplace=True)\n",
        "animal.isna().sum()"
      ],
      "metadata": {
        "id": "-lXJYwTFOvym",
        "outputId": "3256b849-fa47-49c4-c5e4-2b25ebd2d6b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Title       0\n",
              "Abstract    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "human.dropna(inplace=True)\n",
        "human.isna().sum()"
      ],
      "metadata": {
        "id": "Lgx3aXUAO8na",
        "outputId": "7b5f03f0-754d-4648-8cf7-5938daba4b08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Title       0\n",
              "Abstract    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "animal['label'] = 0\n",
        "human['label'] = 1"
      ],
      "metadata": {
        "id": "_tpn0EVmQ9Un"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pretty balanced\n",
        "animal.shape, human.shape"
      ],
      "metadata": {
        "id": "N6vptBYTQ9Gf",
        "outputId": "538530e2-b114-4309-b890-1eaea57f5e25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2151, 3), (2001, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#combine & shuffle the datasets\n",
        "combined_df = pd.concat([animal, human], axis=0)\n",
        "shuffled_combined_df = combined_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "print(shuffled_combined_df.shape)\n",
        "# shuffled_combined_df.head()"
      ],
      "metadata": {
        "id": "V5-0uIFhBzdN",
        "outputId": "7c1c0e43-8d88-4084-d917-4c9bde869090",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4152, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read in input data**"
      ],
      "metadata": {
        "id": "wP10ZvEZeDIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rename the columns so that the relevant column names are 'title' and 'abstract'\n",
        "rename_map = {'Title': 'title', 'Abstract': 'abstract'}\n",
        "shuffled_combined_df.rename(columns = rename_map, inplace = True)\n",
        "print(\"Number of studies in the training dataset: \" + str(shuffled_combined_df.shape[0]))\n",
        "\n",
        "\n",
        "try:\n",
        "  shuffled_combined_df['title_orig'] = shuffled_combined_df['title']\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "  print(\"Error- No title detected! Title is needed!\")\n",
        "  raise\n",
        "\n",
        "\n",
        "# drop any duplicates based on 'title'\n",
        "shuffled_combined_df.drop_duplicates(subset=['title'], inplace=True)\n",
        "print(\"Number of studies in the training dataset after de-dupe: \" + str(shuffled_combined_df.shape[0]))\n",
        "\n",
        "shuffled_combined_df['titleabstract'] = shuffled_combined_df['title'] + \" \" + shuffled_combined_df['abstract']\n",
        "shuffled_combined_df['titleabstract'] = shuffled_combined_df['titleabstract'].str.lower()\n",
        "\n",
        "\n",
        "#sanity check\n",
        "shuffled_combined_df.columns"
      ],
      "metadata": {
        "id": "vDuZ3TtBXauG",
        "outputId": "a4021cec-883c-4510-a902-0e50bab0ed2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of studies in the training dataset: 4152\n",
            "Number of studies in the training dataset after de-dupe: 4148\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['title', 'abstract', 'label', 'title_orig', 'titleabstract'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Preprocessing**"
      ],
      "metadata": {
        "id": "N_ZAynrKSkLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load English tokenizer, tagger, parser and NER\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "OmI9YKOniDR-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lemmatization\n",
        "def lemmatization(titleabstract):\n",
        "    doc = nlp(titleabstract)\n",
        "    lemmalist = [word.lemma_ for word in doc]\n",
        "    return \" \".join(lemmalist)"
      ],
      "metadata": {
        "id": "KahJoKFXk8cY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_combined_df['lemma'] = shuffled_combined_df['titleabstract'].apply(lemmatization)"
      ],
      "metadata": {
        "id": "R6hWMkym-xZy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffled_combined_df.head()"
      ],
      "metadata": {
        "id": "hTSMg7IaVFWZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(titleabstract):\n",
        "    doc = nlp(titleabstract)\n",
        "    no_stopwords = [word.text for word in doc if not word.is_stop]\n",
        "    return \" \".join(no_stopwords)"
      ],
      "metadata": {
        "id": "lPHaYMEteyGr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffled_combined_df['stopwords'] = shuffled_combined_df['lemma'].apply(remove_stopwords)"
      ],
      "metadata": {
        "id": "r51ybR2ZfDrw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffled_combined_df.head()"
      ],
      "metadata": {
        "id": "aB4uAM6dx5pX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train-Test Split: Splits the data into training and test sets.**"
      ],
      "metadata": {
        "id": "OO5KOq9VyZmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into features (X) and target (y)\n",
        "X = shuffled_combined_df['stopwords']\n",
        "y = shuffled_combined_df['label']\n",
        "\n",
        "# X.head()\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "# create a 80-20 split from it\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "train_X.shape, test_X.shape"
      ],
      "metadata": {
        "id": "PKEgVxD-GIZh",
        "outputId": "eb75af2e-a61a-4d63-d966-49ea7ba6e887",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3318,), (830,))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "****"
      ],
      "metadata": {
        "id": "it4RSedVD2K_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initialize the Random Forest classifier**"
      ],
      "metadata": {
        "id": "uKhL19ldFSda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import pi\n",
        "classifier = Pipeline([\n",
        "    ('Vectorizer_tfidf', TfidfVectorizer()),\n",
        "    ('Random Forest', RandomForestClassifier(n_jobs = 1, random_state = 42)) # n_estimators = 100, max_depth = 10, min_samples_split = 2, min_samples_leaf = 1\n",
        " ])\n",
        "\n",
        "\n",
        "# Train the model\n",
        "classifier.fit(train_X, train_y)"
      ],
      "metadata": {
        "id": "0kSC_RhKczrO",
        "outputId": "72975984-d31b-4699-e198-bef576668112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('Vectorizer_tfidf', TfidfVectorizer()),\n",
              "                ('Random Forest',\n",
              "                 RandomForestClassifier(n_jobs=1, random_state=42))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;Vectorizer_tfidf&#x27;, TfidfVectorizer()),\n",
              "                (&#x27;Random Forest&#x27;,\n",
              "                 RandomForestClassifier(n_jobs=1, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;Vectorizer_tfidf&#x27;, TfidfVectorizer()),\n",
              "                (&#x27;Random Forest&#x27;,\n",
              "                 RandomForestClassifier(n_jobs=1, random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=1, random_state=42)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.score(test_X, test_y) * 100"
      ],
      "metadata": {
        "id": "EMbFzQ8mDI7q",
        "outputId": "991f387f-c68d-4623-b2bd-39e0e7b57051",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96.3855421686747"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate the model**"
      ],
      "metadata": {
        "id": "ohSHuKsvKGa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = classifier.predict(test_X)\n",
        "pred[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E-t_KAMGtSl",
        "outputId": "ee681b75-4804-494e-c241-0de9d0d499b9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_y[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7XgsKfUHRBl",
        "outputId": "88802354-af7e-41fc-888b-b728a374969e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149     0\n",
              "1973    0\n",
              "238     1\n",
              "1053    0\n",
              "308     1\n",
              "831     1\n",
              "3897    0\n",
              "1667    1\n",
              "70      1\n",
              "2167    1\n",
              "2649    0\n",
              "1906    0\n",
              "810     0\n",
              "318     1\n",
              "179     0\n",
              "2269    0\n",
              "3394    1\n",
              "3355    1\n",
              "3575    1\n",
              "3153    1\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy: {accuracy_score(test_y, pred)}')\n",
        "print(f'Precision: {precision_score(test_y, pred) *100}')\n",
        "print(f'Recall: {recall_score(test_y, pred)}')\n",
        "print(f'F1-Score: {f1_score(test_y, pred)}')\n",
        "print(f'ROC_AUC: {roc_auc_score(test_y, pred)}')"
      ],
      "metadata": {
        "id": "5MswC83CeS4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "182a6eb7-a22e-453d-cd2f-ef86dca751fb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.963855421686747\n",
            "Precision: 96.22641509433963\n",
            "Recall: 0.966824644549763\n",
            "F1-Score: 0.9645390070921986\n",
            "ROC_AUC: 0.9638044791376266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'classification Report: {classification_report(test_y, pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNEVfy-jIeLS",
        "outputId": "9f0f91e9-43c0-485a-d30a-5bd9685bea13"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.96      0.96       408\n",
            "           1       0.96      0.97      0.96       422\n",
            "\n",
            "    accuracy                           0.96       830\n",
            "   macro avg       0.96      0.96      0.96       830\n",
            "weighted avg       0.96      0.96      0.96       830\n",
            "\n"
          ]
        }
      ]
    }
  ]
}