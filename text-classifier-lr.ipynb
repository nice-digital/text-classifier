{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHnwso1T2vdRBBLQeDGTZW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nice-digital/text-classifier/blob/main/text-classifier-lr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3zDRTxtKAiRD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text classifier Colab**\n",
        "\n",
        "This Colab notebook allows you to categorise a set of scientific papers into two categories. This is experimental code\n",
        "\n",
        "**Note**: Name your training file *training.csv*  and test file *testing.csv* (*title* column should be named 'Title' or 'title' and *abstract* column if present should be named 'Abstract' or 'abstract'), and upload it by pressing the upload button on the top left of the left sidebar. The results will appear in a folder named *RESULTS*. RESULTS folder will be automatically created by the code.\n"
      ],
      "metadata": {
        "id": "J3XQyHVQAmMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Python packages { form-width: \"20%\" }\n",
        "\n",
        "#@markdown Please execute this cell by pressing the _Play_ button\n",
        "#@markdown on the left to download and import third-party software\n",
        "#@markdown in this Colab notebook.\n",
        "\n",
        "#@markdown This installs the software on the Colab\n",
        "#@markdown notebook in the cloud and not on your computer.\n",
        "from IPython.utils import io\n",
        "try:\n",
        "  with io.capture_output() as captured:\n",
        "    %shell pip install scispacy\n",
        "    %shell pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.0/en_core_sci_md-0.5.0.tar.gz\n",
        "    %shell pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bc5cdr_md-0.5.1.tar.gz\n",
        "    %shell pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.1/en_ner_bionlp13cg_md-0.5.1.tar.gz\n",
        "    %shell pip install pyLDAvis==2.1.2\n",
        "    %shell pip install import-ipynb\n",
        "    %shell pip install pandas\n",
        "    %shell pip install shutup\n",
        "\n",
        "except subprocess.CalledProcessError:\n",
        "  print(captured)\n",
        "  raise\n",
        "import shutup\n",
        "shutup.please()\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import spacy\n",
        "import scispacy\n",
        "import pandas as pd\n",
        "from scispacy.abbreviation import AbbreviationDetector\n",
        "\n",
        "from pathlib import Path\n",
        "import collections\n",
        "import csv\n",
        "import multiprocessing as mp\n",
        "from multiprocessing import Pool\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "cpu_count = mp.cpu_count()\n",
        "\n",
        "pd. set_option('display.max_colwidth', None)"
      ],
      "metadata": {
        "id": "yNF5tewRA4Dn",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title File settings to get started { form-width: \"20%\" }\n",
        "\n",
        "#@markdown Please ensure the training.csv and testing.csv are uploaded and execute this cell by pressing the _Play_ button\n",
        "#@markdown on the left\n",
        "\n",
        "#@markdown The training.csv and testing.csv files should have 'title', optional 'abstract' fields. Additionally the file should have a 'target' field\n",
        "#@markdown which indicates whether the title/abstract is an include (coded as 1) or exclude (coded as 0)\n",
        "TRAIN_PATH = 'training.csv'\n",
        "TEST_PATH = 'testing.csv'\n",
        "\n",
        "results_folder = 'RESULTS'\n",
        "RESULTS_FOLDER = results_folder     #***user input\n",
        "if not os.path.isdir(RESULTS_FOLDER):\n",
        "    os.makedirs(RESULTS_FOLDER)\n",
        "RESULTS_PATH = Path(RESULTS_FOLDER)"
      ],
      "metadata": {
        "id": "XDSMaZGDI-Ko",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Read in input data { form-width: \"20%\" }\n",
        "try:\n",
        "    training = pd.read_csv(TRAIN_PATH)\n",
        "    orig_colnames = training.columns\n",
        "    print(orig_colnames)\n",
        "\n",
        "    testing = pd.read_csv(TEST_PATH)\n",
        "\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    raise\n",
        "\n",
        "rename_map = {'Title': 'title', 'Abstract': 'abstract'}\n",
        "training.rename(columns = rename_map, inplace = True)\n",
        "testing.rename(columns = rename_map, inplace = True)\n",
        "print(\"Number of studies in the training dataset: \" + str(training.shape[0]))\n",
        "print(\"Number of studies in the training dataset: \" + str(testing.shape[0]))\n",
        "\n",
        "#Make a note of orig column names, to use when writing out result files\n",
        "#rename the columns so that the relevant column names are 'title' and 'abstract'\n",
        "orig_colnames = [rename_map[col] if col in rename_map else col for col in orig_colnames]\n",
        "\n",
        "try:\n",
        "  training['title_orig'] = training['title']\n",
        "  testing['title_orig'] = testing['title']\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "  print(\"Error- No title detected! Title is needed!\")\n",
        "  raise\n",
        "\n",
        "# drop any duplicates based on 'title'\n",
        "training.drop_duplicates(subset=['title'], inplace=True)\n",
        "testing.drop_duplicates(subset=['title'], inplace=True)\n",
        "print(\"Number of studies in the training dataset after de-dupe: \" + str(training.shape[0]))\n",
        "print(\"Number of studies in the testing dataset after de-dupe: \" + str(testing.shape[0]))\n",
        "]\n",
        "\n",
        "training['titleabstract'] = training['title'] + \" \" + training['abstract']\n",
        "training['titleabstract'] = training['titleabstract'].str.lower()\n",
        "\n",
        "testing['titleabstract'] = testing['title'] + \" \" + testing['abstract']\n",
        "testing['titleabstract'] = testing['titleabstract'].str.lower()"
      ],
      "metadata": {
        "id": "eR8-4xBMB7nQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Fit logistic regression model (in progress) { form-width: \"20%\" }\n",
        "text_clf = Pipeline([\n",
        "                ('tfidfvect', TfidfVectorizer(ngram_range = (3,3), stop_words = 'english')),\n",
        "                ('clf', LogisticRegression(C=100, max_iter = 5000, solver = 'liblinear', penalty = 'l2', class_weight = 'balanced')),\n",
        "               ])\n",
        "model = text_clf.fit(training['titleabstract'].astype(str),y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "0ivxu5aJBbR5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Predict category and evaluate performance (in progress) { form-width: \"20%\" }\n",
        "data = testing['titleabstract'].astype(str)\n",
        "yhat = model.predict(data)\n",
        "yhat_probs = model.predict_proba(data)[:,1]\n",
        "yhat_adjusted = np.zeros(data.shape[0], dtype=int)\n",
        "THRESHOLD = 0.4\n",
        "yhat_adjusted[yhat_probs >= THRESHOLD] = 1\n",
        "\n",
        "report_dict = {}\n",
        "decimal_places = 3\n",
        "report_dict['Accuracy'] = accuracy_score(y_test, yhat_adjusted).round(decimal_places)\n",
        "report_dict['Precision'] = precision_score(y_test,yhat_adjusted).round(decimal_places)\n",
        "report_dict['Recall'] = recall_score(y_test, yhat_adjusted, average = 'binary').round(decimal_places)\n",
        "report_dict['F1-Score'] = f1_score(y_test, yhat_adjusted).round(decimal_places)\n",
        "report_dict['ROC_AUC'] = roc_auc_score(y_test, yhat_adjusted).round(decimal_places)\n",
        "cm = confusion_matrix(y_test, yhat_adjusted)\n",
        "FP = cm[0][1]\n",
        "TN = cm[0][0]\n",
        "FN = cm[1][0]\n",
        "TP = cm[1][1]\n",
        "specificity = (TN / (TN+FP)).round(decimal_places)\n",
        "FPR = (FP/(FP+TN)).round(decimal_places)\n",
        "FNR = (FN/(FN+TP)).round(decimal_places)\n",
        "report_dict['FPR'] = FPR\n",
        "report_dict['FNR'] = FNR\n",
        "report_dict['Specificity'] = specificity\n",
        "\n",
        "print('Classification report:\\n{}'.format(report_dict))\n"
      ],
      "metadata": {
        "id": "hdVqVB-BIfVk",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}